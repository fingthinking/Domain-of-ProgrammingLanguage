一般来说，对于很多学了好几年，甚至于很多年java人来说，一旦看到 OutOfMemeory(简称OOM)，就认为HeapSize不够，然后疯狂的增加-Xmx的值，但是HeapSize只是其中一个部分，当你去做一 个实验，也就是java启动时直接在程序中疯狂的new 一些线程出来，直到内存溢出，当-Xms -Xmx设置得越大的时候，得到的线程个数会越少，为什么呢？因为OOM并不是HeapSize不够而导致的，而由很多种情况。

首先看下操作系统如何划分内存给应用系统，其实在Win 32、Linux 32的系统中，地址总线为32位的理论上应该可以支持4G内存空间，但是当你在Win 32上设置初始化内存如果达到2G，就会报错，说这个块空间没法做，首先默认的Win32系统，会按照50%比例给予给Kernel使用，而另一部分给应 用内存，也就是说操作系统内核部分不论是否使用，这一半是不会给你的，而还有2G呢，它在系统扩展的部分，也就是并非Kernel的部分，有很多静态区域 和字典表的内容，所以要划分一个连续的2G内存给JVM在Win 32上是不可能的，Win 32提出了一种Win 32 3G模式，貌似可以划分3G空间，其实它只是将内核部分缩小也就是管理部分缩小，也就是将一部分划分到外部来使用，而且Win 32习惯在内存2G的位置做一些手脚，让你分配连续2G没有可能性，一般来说在Win 32平台上，在物理内存足够的情况下给JVM划分的空间一般是1.4~1.5G左右，具体数据没有测试过；而Linux 32类似于Win 32 3G模式，但是它还是一般情况下分布不凌乱的情况下，一般可以给JVM划分到2G的大小。Linux 32 Hugemem是一个扩展版本，可以划分更大的空间，但是需要付出一些其他的代价，理论上可以支持到4G给应用，也就是Kenel是独立 的；Solaris x86-32和AIX 32等系统，也类似于Linux 32平台一样。
 
  为什么还要预留一些空间出来呢？这些空间给谁？
  当你申请一个线程的时候，它的除了线程内部对象的开销外，线程本身的开销，是需要OS来调度完成，一般来说，会在OS的线程与虚拟机内部有都有一个一一对 应的，但是会根据操作系统不同有所变化，有些可能只有一个，总之heapSize外的那部分空间是跑不掉的，它放在哪里呢？就是放在Stack中的，所以 上文中的-Xss就是设置这个的，在jdk 1.5以后，每个线程的大小被默认设置为1M的stack开销，我们习惯将这个开销降低。
 
  好了知道了指针、线程是在heapSize外部的，还有什么呢？
  当你自己使用native方法，也就是JNI的时候，调用本地其他语言，如C、C++在程序中使用了malloc等类似方法开辟的内存，都不是在 heapSize中的，而是在本地OS所掌控的，另外这部分空间如果没有相应的释放命令，就需要在对应finalize方法内部调用其他的native方 法来完成对相应对象的释放，否则这部分将成为OS级别的内存泄露，直到JVM进程重启或者宕机为止(操作系统会记录下进程和相应线程和堆内存的关联关系， 但是进程再没有释放前，OS也是不会回收这部分内存的)。
  另外在使用JavaNIO以及JDBC、流等系列操作时，当形成与终端交互时，会在另一个位置形成一个内存区域，这些内存区域都不在HeapSize中。
  所以常见的OOM现象有以下几种：
  1、heapSize溢出，这个需要设置Java虚拟机的内存情况
  2、PermSize溢出，需要设置Perm相关参数以及检查内存中的常量情况。
  3、OS地址空间不够，也就是没有那么多内存分配，这个一般是启动时报错。
  4、Swap空间频繁交互，进程直接被crash掉，在不同操作系统中会体现不同的情况。
  5、native Thread溢出，注意线程Stack的大小，以及本身操作系统的限制。
  6、DirectByteBuffer溢出，这一类一般是在做一些NIO操作的时 候，或在某种情况下使用ByteBuffer，在分配内存时使用了allocateDirect以及使用一些框架间接调用了类似方法，导致直接内存的分配 (如mina中使用IoByte去调用，当参数设置为true的时候就分配为直接内存，所谓直接内存就是又OS定义的内存，而不需要从程序间接拷贝一次再 输出的过程，提高性能，但是如果没有手动回收是回收不掉的)，导致的Buffer问题，如输出大量的内容，输入大量的内容，此时需要尽量去尝试限制它的大 小。
 
使用非常多的工具区检测Java的内存如：jstat(只能看HeapSize和 PermSize)、jmap(很细的东西)、jps(java的ps -ef呵呵)、jdb(这个不是监控工具哈，这个是debug工具)、jprofile(图形支持，但是可以远程连接)等等；jconsole(可以看到 heapsize、permsize+native mem size(这这里叫做：non-heapsize)等等的使用的趋势图)、visualvm(极为推荐的东西，图形化查看，你可以查看到内存单元分配、交 换、回收、移动等等整个过程，非常清晰展现jvm的全局资源)、另外pmap可以展现非常清晰的资料，可以精确到某一个java进程内部的每一个细节，而 且可以看到heapsize只是其中很小一部分(在solaris操作系统上看得最齐全，LINUX下有些进程可能看不太懂)；也可以在/proc/进程 号/maps中查看(这里可以看到内存地址单元的起始地址，包含了reserved的地址范围和commited的地址范围)，全局资源使用操作系统 top命令和free命令看；IBM有一个GCMV免费下载工具也很好；Win32有一个WMMap工具都是很好的工具
 
 
使用相应的工具观察相应的内容，当观察到内存的使用从无到有，上升，然后处于一个平稳 趋势，那么这个JVM应该是较为稳定的；如果发现它经过一段平滑期后，又出现飙升，这个必然是有问题的，至于什么问题，根据前面的学下和实际情况我们可以 去分析；当它开始后，平滑过程，出现缓慢上升的过程，但是始终会上升到极点，那么一个是需要知道物理内存时候可用，另一个就是少量的内存泄露(JVM现代 也有内存泄露，只是它的内存泄露并非C、C++中的内存泄露)。

```
Heap
 PSYoungGen      total 343552K, used 335874K [0x000000076ab00000, 0x0000000793000000, 0x00000007c0000000)
  eden space 149504K, 100% used [0x000000076ab00000,0x0000000773d00000,0x0000000773d00000)
  from space 194048K, 96% used [0x0000000781900000,0x000000078cf00a88,0x000000078d680000)
  to   space 225280K, 0% used [0x0000000773d00000,0x0000000773d00000,0x0000000781900000)
 ParOldGen       total 705024K, used 476040K [0x00000006c0000000, 0x00000006eb080000, 0x000000076ab00000)
  object space 705024K, 67% used [0x00000006c0000000,0x00000006dd0e2290,0x00000006eb080000)
 Metaspace       used 3194K, capacity 4494K, committed 4864K, reserved 1056768K
  class space    used 345K, capacity 386K, committed 512K, reserved 1048576K
```

      我曾经在文章中说到任何系统最多使用的数据类型必然是String，不管做什么，所以在String的处理上很有研究，推荐使用java的朋友在大量使用 对比的时候不要用equals，而推荐使用intern()，但是我最近发现我错了，我这里给大家道歉，因为可能会误导很多朋友；下面说明下这个东西为什 么？
     首先我开始自己怀疑自己的时候是想说，如果intern可以做到高效，那么equals是不是在String中就没有存在的必要了呢，当时对于我理解仅仅 为常量池的一个地址对比，好比是两个数字的compare，仅仅需要CPU的单个指令即可完成；于是我开始做了两个实验，一个是最原始，最初级的方法采用 单线程循环1000000次调用equals与intern等值对比，并且采用了不同长度的字符串去做比较，发现equals竟然比intern要快，而 且随着字符串长度的增加，equals会明显快与intern，然后使用多线程测试也是得到一样的效果，我首先很不敢相信自己坚持的理论被彻底和谐了，后 来冷静下来必须需要面对，通过很多权威资料的阅读，我发现我对JVM常量池的理解还只是一点点皮毛而已，所以我做了更加深入的研究。
    原来intern方法被调用时是在Perm中的String私有化常量池中寻找相应的内容，而寻找虽然可以通过hash定位到某些较小的链表中，但是还是 需要在链表中逐个对比，对比的方法仍然是equals，也就是抛开hash的开销，intern最少要与里面的0到多个对象进行equals操作，而且如 果不存在，还要在常量池开辟一块空间来记录，如果存在则返回地址，也就是常量池保证每个String常量是唯一的，这个开销当然大了，而且如果使用在业务 代码中将会导致Perm区域的不断增加；
    于是，我又反过来想了：既然equals比他效率高，为啥还要用intern呢？而且equals的那个算法对于长字符串逐个字符对比的过程我实在是难以 入目；而且也实在是觉得不甘心自己的理论就这么容易被和谐掉，因为自己已经在不少程序中这样用过，这样我岂不是犯下大错了，因为自己参与过的项目的确太多 了，而且有类似的代码我写入了框架中，最终发现我可能错了一半，也就是历史上的记录可能我有一半类似的代码是错误的；为什么呢？intern还是有用的， 我先做了一个测试，那就是，用一个已经intern好的对象，让他与一个常量做等值，循环次数和上面一样，结果我预料的结果发生了，那就是比equals 快出了N多倍数，随着长度的增加，会体现出更加明显的优势，因为intern对比的始终是地址，和长度无关，于是我想到了如何使用它，就是在程序中返回通 过字符串类似于数字一样的类型判定时，如：做一个sqlparser的时候，经常根据数据类型做不同的动作，这样如果用equals会在每次循环时付出很 多开销，尤其是很多数据库的类型非常多，最坏的是从上到下每个字符串匹配一次，当然长度不等开销很小，长度相等开销就大了；intern我就将这些 schema信息预先intern掉，也就是他们已经指向了常量池，当再真正匹配时，就不需要用intern了，而是直接匹配，也就是将这个开销放在初始 化的过程中，运行时我们不去增加它的开销。
    所以，个人是犯下一个错误，并且以前还很张扬的到处宣传，呵呵，现在觉得有点傻，希望在看到某些推荐用什么新东西的时候，千万不要在没有研究明白他就去用 它，甚至于滥用它，至少要经过一些简单的测试，不过对于现代很多复杂的东西，一些简单的测试已经不足以说明问题，就像Lock与Synchronize的 开销一样，如果采用简单的循环的话，你会发现新版本的Lock的开销将会比Synchronized的开销更加大，它适合的是并发，读写的并发，所以真正 要弄清楚还是研究内在。
